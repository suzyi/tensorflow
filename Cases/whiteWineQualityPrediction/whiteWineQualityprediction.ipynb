{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White wines classification using neural network\n",
    "gery, July 3, 2018.\n",
    "\n",
    "This notebook includes how to import csv file and convert it into array so that Tensorflow is able to deal with.\n",
    "\n",
    "The dataset comes from [winequality-white.csv](http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - 1 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('winequality-white.csv')\n",
    "reader = csv.reader(csvfile, delimiter=';')\n",
    "temp = []\n",
    "for row in reader:\n",
    "    temp.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 12)\n",
      "<type 'numpy.ndarray'>\n",
      "[7.000e+00 2.700e-01 3.600e-01 2.070e+01 4.500e-02 4.500e+01 1.700e+02\n",
      " 1.001e+00 3.000e+00 4.500e-01 8.800e+00 6.000e+00]\n"
     ]
    }
   ],
   "source": [
    "data = np.array(temp[1:], dtype = float)\n",
    "print np.shape(data)\n",
    "print type(data)\n",
    "print data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - 2 - How many examples of each kind of different quality wine do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.array([0, 0], dtype = int)\n",
    "for score in range(11):\n",
    "    temp = 0\n",
    "    for j in data[:, 11]:\n",
    "        if j == score:\n",
    "            temp = temp + 1\n",
    "    table = np.vstack([table, [score, temp]])\n",
    "table = table[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality number\n",
      "[[   0    0]\n",
      " [   1    0]\n",
      " [   2    0]\n",
      " [   3   20]\n",
      " [   4  163]\n",
      " [   5 1457]\n",
      " [   6 2198]\n",
      " [   7  880]\n",
      " [   8  175]\n",
      " [   9    5]\n",
      " [  10    0]]\n"
     ]
    }
   ],
   "source": [
    "print \"quality\",\"number\"\n",
    "print table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sio.savemat('whitewineQualityPrediction', {'trainingData': trainingData, 'testData': testData})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - 3 - Respectively pick up wines whose score lines in 5 to 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'table5': np.array(range(12)), 'table6': np.array(range(12)), 'table7': np.array(range(12))}\n",
    "for score in range(5, 8):\n",
    "    index = 0\n",
    "    for j in data[:, 11]:\n",
    "        if j == score:\n",
    "            dic['table' + str(score)] = np.vstack([dic['table' + str(score)], data[index, :]])\n",
    "        index = index + 1\n",
    "    dic['table' + str(score)] = dic['table' + str(score)][1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1457, 12)\n",
      "(2198, 12)\n",
      "(880, 12)\n"
     ]
    }
   ],
   "source": [
    "for score in range(5, 8):\n",
    "    print np.shape(dic['table' + str(score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4535"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1457+2198+880"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - 3 - Randomly pick up training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = np.array(range(12))\n",
    "testData = np.array(range(12))\n",
    "rate = .7  # The proportion of training examples over whole examples\n",
    "\n",
    "# shuffle the data\n",
    "for score in range(5, 8):\n",
    "    m = np.shape(dic['table' + str(score)])\n",
    "    index = range(m[0])\n",
    "    random.shuffle(index)\n",
    "    trainingData = np.vstack((trainingData, dic['table' + str(score)][index[:np.int(np.round(rate*m[0]))], :]))\n",
    "    testData = np.vstack([testData, dic['table' + str(score)][index[np.int(np.round(rate*m[0])):], :]])\n",
    "trainingData = trainingData[1:, :]\n",
    "index = range(np.shape(trainingData)[0])\n",
    "random.shuffle(index)\n",
    "trainingData = trainingData[index, :]\n",
    "testData = testData[1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Classification using neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - 1 - Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_steps = 500\n",
    "display_step = num_steps/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 100 # 1st layer number of neurons\n",
    "n_hidden_2 = 100 # 2nd layer number of neurons\n",
    "num_input = np.shape(trainingData)[1] - 1\n",
    "num_classes = 1\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create linear model\n",
    "# def neural_net(x):\n",
    "#     # Hidden fully connected layer with 256 neurons\n",
    "#     layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "#     # Hidden fully connected layer with 256 neurons\n",
    "#     layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "#     # Output fully connected layer with a neuron for each class\n",
    "#     out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "#     return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.sigmoid(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.sigmoid(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.norm(logits - Y, 2)\n",
    "# loss_op = tf.reduce_mean(logits - Y)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.round(logits), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "prediction = tf.round(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - 2 - Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Training Loss= 988.8809, Training Accuracy= 0.000\n",
      "Step 50, Training Loss= 40.0521, Training Accuracy= 0.485\n",
      "Step 100, Training Loss= 39.7664, Training Accuracy= 0.486\n",
      "Step 150, Training Loss= 37.1872, Training Accuracy= 0.485\n",
      "Step 200, Training Loss= 36.4443, Training Accuracy= 0.485\n",
      "Step 250, Training Loss= 40.8473, Training Accuracy= 0.468\n",
      "Step 300, Training Loss= 36.3336, Training Accuracy= 0.485\n",
      "Step 350, Training Loss= 35.2286, Training Accuracy= 0.485\n",
      "Step 400, Training Loss= 38.6021, Training Accuracy= 0.445\n",
      "Step 450, Training Loss= 39.3795, Training Accuracy= 0.449\n",
      "Step 500, Training Loss= 34.8642, Training Accuracy= 0.485\n",
      "Optimization Finished!\n",
      "('Testing Accuracy:', 0.48455882)\n",
      "Predicted labels:\n",
      "[[6. 6. 6. ... 6. 6. 6.]]\n",
      "True testing labels:\n",
      "[5. 5. 5. ... 7. 7. 7.]\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: trainingData[:,0:num_input], Y: trainingData[:,num_input:num_input + 1]})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: trainingData[:,0:num_input],\n",
    "                                                                 Y: trainingData[:,num_input:num_input + 1]})\n",
    "            print(\"Step \" + str(step) + \", Training Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for MNIST test images\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X: testData[:,0:num_input],Y: testData[:,num_input:num_input + 1]}))\n",
    "    \n",
    "    # comparison between true tesing labels and predicted labels\n",
    "    print \"Predicted labels:\"\n",
    "    print sess.run(prediction, feed_dict={X: testData[:,0:num_input]}).T\n",
    "    print \"True testing labels:\"\n",
    "    print testData[:, num_input]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernelForTF",
   "language": "python",
   "name": "kernelfortf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
